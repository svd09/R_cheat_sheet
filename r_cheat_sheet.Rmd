---
title: "R script:Cheat-sheet"
date: "`r Sys.Date()`"
author: Salil V Deo MD (svd14 at case dot edu)
output:
  rmdformats::readthedown:
    highlight: kate
    
---


```{r setup, include=FALSE}
library(knitr)
library(rmdformats)

## Global options
options(max.print="75")

opts_chunk$set(echo=TRUE,
	             cache=TRUE,
               prompt=FALSE,
               tidy=TRUE,
               comment=NA,
               message=FALSE,
               warning=FALSE)

opts_knit$set(width=75)

```



This cheat-sheet is a guide to the commonly needed R-code for initial data cleaning and data restructuring. 

## Importing data into Rstudio from various formats:

```{r}
library(tidyverse) # import csv

library(haven) # import SAS, SPSS, STATA 

library(readxl) # import excel files

library(stringr); library(magrittr);library(ggthemes)

library(naniar);library(mice);library(Amelia);library(miceadds)
library(data.table)

```

Importing syntax:

*csv* -`read_csv("df.csv")`

*SAS* - `read_sas("df.sas7bdat")`

*STATA* - `read_dta("df.dta")`

*SPSS* - `read_sav("df.sav")`

*Excel* - `read_excel("df.xlxs", sheet = 1)`

For excel files, the sheet argument can be either a number of a string with the name of the sheet.

## Converting variable column names to lowercase:

Column names can all be converted to lower or uppercase as needed.
R is case sensitive , hence , columns *year, Year, YEAR* are actually the name of 3 uinque columns in R.


```{r}

df <- mtcars

# to change to UPPER

names(df) <- toupper(names(df))

names(df)

# to change to lower

names(df) <- tolower(names(df))

names(df)

```



```{r}

# to make only first letter CAPITAL for every colname.

# using the stringr library

library(stringr)

names(df) <- stringr::str_to_title(names(df))

names(df)


```

## Look at some dplyr verbs:

### Filter

*Filter* helps to select rows for an argument.

```{r}

# again using mtcars.

summary(df$Mpg)

summary(df$Cyl)

# now to keep only rows with Mpg < 20.

df2 <- df %>% filter(Mpg < 20)

summary(df2$Mpg)

# to keep only Mpg < 20 and Cyl == 6

df3 <- df %>% filter(Mpg < 20) %>%
  filter(Cyl == 6)

summary(df3[, c("Mpg","Cyl")]) # using summary like this can provide the summary of only those columns that you want.

```

### Select:- 

*Select* will keep only those columns in the argument.

```{r}

# using whole name of columns.

df4 <- df %>% select(Mpg, Cyl)

str(df4) # now contains only these two columns.

# now to only select according to type of column.
# am going to convert cylinder to factor.

df$Cyl <- as.factor(df$Cyl)

df4 <- df %>% select_if(is.factor)

str(df4)

# on Cyl included as that one is the only factor in the df.

df4 <- df %>% select_if(is.numeric)

str(df4) # now all but Cyl is included as that is a factor.

# we can also choose based on the name or part of the column name.

df4 <- df %>% select(contains("Mp"))

str(df4) # as only Mpg contains "Mp" that is the only column selected.

df4 <- df %>% select(starts_with("W"))

str(df4) # as Wt is the only column that starts with W.

df4 <- df %>% select(ends_with("c"))

str(df4)

```

### Mutate:-

*Mutate* will help to create new variables. I do not use it as much.
Rather if find $ifelse$ very useful to create variables using arguments based on another variables.

```{r}

summary(df)

# now to create new variable gas_guzzler when Mpg < 20.

df2 <- df %>% mutate(gas_guzzler = ifelse(Mpg < 20, 1, 0))

str(df2) 

# to use mutate, we need to create a new df. Rather than using mutate, I prefer to use base R and ifelse.

df$gas_guzzler <- with(df, ifelse(Mpg < 20, 1, 0))

summary(df$gas_guzzler) # so using this code, I can create new variables without having to keep creating new dataframes. I know some code to create many variables at once, but I like to create 1 variable at a time and code iteratively.


# ifelse arguments can be nested to create as many values as needed.
# this may be the alternative to fct_recode.

df$gas_guzzler2 <- with(df, ifelse(Mpg > 30, 0 , 
  ifelse(Mpg < 20, 1, 2)
)) 


df %>% count(gas_guzzler2) # do, now have this column as factor with 3 levels - 0/1/2

# with this coding, the column is not converted to factor type , but there is really no need to convert it. If some functions need it only as a factor, then we can easily convert it using as.factor()...

```

*as.factor, as.numeric* can be used to change the type of the variable if needed. 

While there are many other dplyr verbs, I have not used them very often and from my experience, are not much needed to regular data cleaning and variable creation.


## Working with Dates:

The *lubridate* package is excellent for working with dates.

```{r, message = FALSE}
library(lubridate)

# get dummy dataset with dates.

df <- read_csv("H:\\R_cheat_sheet\\R_cheat_sheet\\date_df.csv")

glimpse(df) 

# now first to declare the columns as date formats.

df$date_of_surgery <- as_date(df$date_of_surgery)

df$dob <- as_date(df$dob)

df$last_contact_date <- as_date(df$last_contact_date)
  

# now before we use these columns we can do some simple date 
# function.

today() # this is todays date, or when the rmarkdown was last knitted. 

# Dates in R are presented by convention as ymd.
# ymd format is unambigious as it is conventionally used for date in most software programs.

ymd(20210128) # this can be used to change the numbers to dates.

# to extract the day, month or year from a date.

month("2019-02-10")

year("2011-10-01")

day("2011-10-01")


# this can be used to create new columns...

df$dob_year = year(df$dob)
  
head(df$dob_year, 5)

# we can use month or day to similarly extract the day or month and that can be inserted into a new column.

```

Subtracting dates to get time in days, years.

```{r}

# to subtract dates.

df$age_at_surgery <- (df$dob %--% df$date_of_surgery)/ddays(1)

# now to convert to years, divide by 365.24

df$age_years <- df$age_at_surgery/365.24 # the .24 accounts for the leap years.


# we conventionally present age a whole number.

df$age_years <- round(df$age_years, 0)

summary(df$age_years) # age as whole numbers from the dob and date of surgery.

# if we want to extract months, we can divide by 30.
```
*Lubridate* also has excellent functions to work with hh:mm:ss to calculate difference between date:times. I have not used those much.

```{r}


# to obtain age of a patient today, we can use the today function...

df$cur_age <- (df$dob %--% today())/ddays(1)

df$cur_age <- round((df$cur_age/365.24),0)

summary(df$cur_age) # of course all patients lived, so we have a patient aged 103 years :))

```

## Missing data:

*naniar* , *mice*, *micetools* and *Amelia* provide excellent functions for handling and dealing with missing data.

```{r}

# create a simple dataset.

df <- tibble(x = c(1,2,3,NA,4,5,999,999),
             y = c(NA,NA,3,4,5,999,999,10),
             name = c("a","b",NA,"c",NA,NA,NA,"d"))

print(df)


# determine percent missing in each variable

naniar::miss_var_summary(df) # a nice df of number and % missing for each variable.

# however, if we see, we have have some 999 that likely are missing.
# so, we need to conver them to missing.

df2 <- df %>% naniar::replace_with_na_all( condition = ~.x == 999)

print(df2) # all 999 replaced with NA for all columns.

# if we want to now replace NA for a number say -99.


print(df2)

df3 = df2 %>% replace_na(list(x = -99, y = -99)) # we want to replace NA with -99 as these are numeric columns.

print(df3)

```

Now, we will use mice for imputation of a small dataset with missing values.

```{r}

df <- tibble(x = c(1,2,NA,4,5,5,6,7,NA,NA,4,5,6),
             y = c(0,0,1,1,1,NA,NA,0,1,1,0,NA,1),
             z = c("abc","abc","cde","fgh",NA,NA,NA,"cde","abc",NA,"fgh",NA,"fgh"))

print(df)


# this is a dataset, where each column has missing values.
# x = numeric, y = factor, z = character vars.

# before using mice it is important to set the variable as either numeric or factors for the vars that have numbers.
# from y = 0/1 it is clear that this is a factor.

df$y = factor(df$y)


imp <- mice(data = df, m = 5)

summary(imp)

# get the 1st dataset.

# to convert the datasets into 1 long dataset.

df_long <- complete(imp, "long")

head(df_long,10) # we can see from this that z column is not imputed.
# mice cannot impute for characters.
# we need to convert the character variable into a numeric factor variable prior to imputation.

df$z[df$z == "abc"]<- 1
df$z[df$z == "cde"]<- 2
df$z[df$z == "fgh"]<- 3

df$z <- factor(df$z, levels = c(1,2,3), labels = c('abc','cde','fgh'))
               
imp2 <- mice(data = df, m = 5)

summary(imp2)
               
# now looking at summary, it is clear that all variables with missing values have not been imputed. mice uses pmm for numeric (var x)/ integers and logreg method for factors (var y). if the variable contains more than two levels, then it uses polyreg (var z)

df_long2 <- complete(imp2, "long")

head(df_long2,10) # now we can see that there is no missing data.

naniar::miss_var_summary(df_long2) # confirmed.


# to include the original dataset with the long formatted imputed datasets.

df_long_original <- complete(imp2, include = T, "long")

str(df_long_original) # here .imp == 0 is the original dataaset.

# from this we can then use filter to get each separate dataset.

```

After imputation, we want to run a model and then be able to pool the results of the model.

If we consider in the dataset *df* that x = postoperative hospital stay, y = procedure performed and z = zip code, then we can use zip code and procedure performed to model postoperative hospital stay.

```{r}

model <- with(imp2, lm(x ~ y + z))

summary(model) # this will not provide pooled results.

res <- mice::pool(model)

model_summ <- summary(res)

# the summary provide the results including estimate/coef, SE, p-value.
# CI can be obtained using the following method:

str(model_summ)



```

```{r}


# pooled_ci is a function to pool lm, glm or coxph model using Rubins rules.
# the function returns statement describing which model was fit and 
# a tibble with covariate name, estimate, CI and p-value.
# @parameters in the function:
# df = fitted model fitted using imputed mids object
# model = specify character statement of either glm, lm, or coxph

pooled_ci <- function(df, model = c("glm","lm","coxph")){
  
  
   stopifnot(is.data.frame(df))
   stopifnot(is.character(model))
  
  if(model == "glm"){
  est <- exp(df$estimate)
  
  se <- df$std.error
  
  lci <- exp(est - 1.96*se)
  uci <- exp(est + 1.96*se) 
  
  result <- tibble(variable = df$term,
                OR = exp(df$estimate),
                OR_lower95 = lci, 
                OR_upper95 = uci, 
                p_value = df$p.value)
  return(list(result, "results of pooling glm object"))
  } 
  if(model == "lm"){
    est <- df$estimate
    se <- df$std.error
    
    lci <- est - 1.96*se
    uci <- est + 1.96*se 
    
    result <- tibble(variable = df$term,
                  est = df$estimate,
                  lower95 = lci, 
                  upper95 = uci, 
                  p_value = df$p.value)
    
    
    return(list(result,"results of pooling lm object"))
    
  }

if(model == "cox"){
   
     est <- exp(df$estimate)
  
  se <- df$std.error
  
  lci <- exp(est - 1.96*se)
  uci <- exp(est + 1.96*se) 
  
  result <- tibble(variable = df$term,
                HR = exp(df$estimate),
                HR_lower95 = lci, 
                HR_upper95 = uci, 
                p_value = df$p.value)
  
  return(list(result, "results of pooling coxph object"))
} 

}


```



```{r}
res <- pooled_ci(model_summ, model = "lm")

res
```

The meld function in Amelia can be used if the models that we want to use are not included in the above function. In that case, the algorithm of work would be (1) get imputed datasets with mice (2) separate the datasets (3) fit model individually for each (4) make a list of the estimates and standard errors from each model (5) use meld function in Amelia to get pooled estimates with standard error and p-values.

Example of this will follow later...

## Plotting functions in ggplot2

Create a histogram using ggplot2

```{r}

df <- mtcars


ggplot(data = df, aes(x = mpg)) + 
   geom_histogram(color = "blue", fill = "gray") +  
# provide fill for filling bars and color for border of bars  
   labs(title = "Histogram of MPG from mtcars dataset", x = "Count", y = "Miles Per Gallon", 
        caption = "Data abstracted from the World Health Organisation") + 
# labelling of the histogram
theme(plot.title = element_text(hjust = 0.5)) + 
# center the plot title 
theme(plot.caption = element_text(face = "italic",size = 8)) 

```

When using theme from the *ggthemes*, remember that the theme will have its own default regarding font type, font size ...
Hence, to maintain consistent format, user can create own theme using *theme_foundation* provided in theme library.

## Saving ggplot2 with high resolution and custom spefications:

The plot created above can now be saved with desired resolution and 
plot dimensions and plot type.

```{r}

# recreate plot again and put it into an object a

df <- mtcars


a <- ggplot(data = df, aes(x = mpg)) + 
   geom_histogram(color = "blue", fill = "gray") +  
# provide fill for filling bars and color for border of bars  
   labs(title = "Histogram of MPG from mtcars dataset", x = "Count", y = "Miles Per Gallon", 
        caption = "Data abstracted from the World Health Organisation") + 
# labelling of the histogram
theme(plot.title = element_text(hjust = 0.5)) + 
# center the plot title 
theme(plot.caption = element_text(face = "italic",size = 8)) 

# now to save the plot.

# ggsave(a, 
#        height = 5,
#        width = 7,
#        filename = "MYPATHHERE.plottype",
#        units = "in",
#        dpi = DESIRED_PLOT_DPI_HERE)

# standard dpi for color plots should be between 600 - 1200 dpi.



```

## Base R method to save a ggplot2 graph 

This is the base R method to save a ggplot2 graph. Naturally, it can be also used to save a base R plot. This should be the default method to save a Kaplan Meier plot created using the *ggsurvplot* function in *survminer* package as it will work when there is a risk table below the plot. The *ggsave* function will not work when there is a risk table below the KM plot created with *ggsurvplot*.

```{r}

# tiff('MYPATHHERE.tiff',
#      height = 5,
#      width = 7,
#      device = "tiff",
#      res = 900)
# 
# # PRINT GGPLOT2 OBJECT NAME HERE
# 
# 
# dev.off()

# to save as PDF, change call to pdf and device to pdf.

# for survminer graphs---

# tiff('MYPATHHERE.tiff',
#      height = 5,
#      width = 7,
#      device = "tiff",
#      res = 900)
# 
# print(PRINT GGPLOT2 OBJECT NAME HERE)
# 
# 
# dev.off()

```

## Moving columns around in the dataset

If we want to move columns around to keep those use more in the front

```{r}

moveme <- function (invec, movecommand) {
  movecommand <- lapply(strsplit(strsplit(movecommand, ";")[[1]], 
                                 ",|\\s+"), function(x) x[x != ""])
  movelist <- lapply(movecommand, function(x) {
    Where <- x[which(x %in% c("before", "after", "first", 
                              "last")):length(x)]
    ToMove <- setdiff(x, Where)
    list(ToMove, Where)
  })
  myVec <- invec
  for (i in seq_along(movelist)) {
    temp <- setdiff(myVec, movelist[[i]][[1]])
    A <- movelist[[i]][[2]][1]
    if (A %in% c("before", "after")) {
      ba <- movelist[[i]][[2]][2]
      if (A == "before") {
        after <- match(ba, temp) - 1
      }
      else if (A == "after") {
        after <- match(ba, temp)
      }
    }
    else if (A == "first") {
      after <- 0
    }
    else if (A == "last") {
      after <- length(myVec)
    }
    myVec <- append(temp, values = movelist[[i]][[1]], after = after)
  }
  myVec
}

# this is primarily for vectors 
# eg. moveMe(names(df),"g first") = will insert g as the first column
# moveMe(names(df), "g first; a last; e before c") = will do exactly as written in the code
# for dataframes , we need to use: df[moveMe(names(df),"g first")]
```


```{r}

df <- mtcars

names(mtcars)

df2 <- df[moveme(names(df), "disp first")]

names(df2) # now df2 contains disp as the first column.

df2 <- df[moveme(names(df), "drat last")]

names(df2) # now drat is last
```
 
*moveMe* function will move the column to the first or last position of the dataset.

## Example using data.table package which has a function similar to the LIKE in SQL.

```{r}
## Create the data.table:
DT = data.table(Name=c("Mary","George","Martha"), Salary=c(2,3,4))

## Subset the DT table where the Name column is like "Mar%":
DT[Name %like% "^Mar"]
##      Name Salary
## 1:   Mary      2
## 2: Martha      4

```


